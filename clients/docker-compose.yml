services:
  clients_service:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile
    container_name: clients_service
    ports:
      - "3004:3004"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    env_file:
      - .env.production
    networks:
      - clients_network

  postgres:
    image: postgres:14.18
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER_FILE: /run/secrets/postgres_user
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
      POSTGRES_DB: event_tickets
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "$(cat /run/secrets/postgres_user)"]
      interval: 10s
      timeout: 5s
      retries: 10
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - .docker/clients.sql:/docker-entrypoint-initdb.d/clients.sql
    networks:
      - clients_network
    secrets:
      - postgres_password
      - postgres_user

  kafka:
    image: "confluentinc/cp-kafka:latest"
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_NODE_ID=1
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:29093
      - KAFKA_LISTENERS=PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk
      - KAFKA_CREATE_TOPICS=CLIENT_CREATED_TOPIC:1:1,SEND_TICKET_TOPIC:1:1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-topics --bootstrap-server localhost:9092 --list || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - clients_network

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    ports:
      - "16686:16686"
      - "4317"
    networks:
      - clients_network

  collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: collector
    volumes:
      - .docker/otel-collector-config.yaml:/etc/otelcol-contrib/config.yaml
    command: --config /etc/otelcol-contrib/config.yaml
    ports:
      - 4318:4318
      - 4317:4317
      - 8889:8889 # Prometheus exporter metrics
    restart: always
    depends_on:
      - jaeger
      - prometheus
    networks:
      - clients_network

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus_data:/prometheus
      - .docker/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - clients_network

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3006:3000"
    environment:
      - GF_SECURITY_ADMIN_USER__FILE=/run/secrets/grafana_user
      - GF_SECURITY_ADMIN_PASSWORD__FILE=/run/secrets/grafana_password
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - clients_network
    secrets:
      - grafana_user
      - grafana_password

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.0.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    networks:
      - clients_network

  kibana:
    image: docker.elastic.co/kibana/kibana:9.0.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - clients_network

  filebeat:
    image: docker.elastic.co/beats/filebeat:9.0.0
    container_name: filebeat
    user: root
    volumes:
      - ./.docker/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - elasticsearch
    networks:
      - clients_network

  apm_server:
    image: docker.elastic.co/apm/apm-server:9.0.1
    container_name: apm_server
    depends_on:
      - elasticsearch
      - kibana
    environment:
      - output.elasticsearch.hosts=["http://elasticsearch:9200"]
      - apm-server.auth.anonymous.enabled=true
      - apm-server.auth.anonymous.allow_agent=["opentelemetry"]
      - apm-server.auth.anonymous.allow_service=["app"]
      - apm-server.kibana.enabled=true
      - apm-server.kibana.host=http://kibana:5601
      - setup.kibana.host=http://kibana:5601
    ports:
      - "8200:8200"
    networks:
      - clients_network

volumes:
  grafana_data:
  prometheus_data:
  postgres_data:
  kafka_data:
  es_data:

networks:
  clients_network:

secrets:
  postgres_password:
    file: .docker/secrets/postgres_password.txt
  postgres_user:
    file: .docker/secrets/postgres_user.txt
  grafana_user:
    file: .docker/secrets/grafana_user.txt
  grafana_password:
    file: .docker/secrets/grafana_password.txt
